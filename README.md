# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**

The dataset used in this project is the UCI Bank Marketing dataset which contains data about a marketing campaign of a financial institution. The goal here is to predict and identify clients who are likely to start or subscribe a term deposit account. This will go a long way to improve future marketing campaigns for the bank as it will predict the likelihood of a client to subscibe to a product that is being adverstised.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**
The best performing model was the VotingEnsemble with an accuracy of 0.9171 which was gotten from AutoML.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
The pipeline can be shown in 5 steps:
- **Data Acquisition:**
The data was acquired from a provided url using `TabularDatasetFactory`. 

- **Data Wrangling/Cleaning**
The acquired data was extracted and cleaned with the `clean_data` method. The data was divided into inputs(x) and target(y).

- **Train/Test Split**
The data was then split into train and test data using scikit learn's `train_test_split`. 75% for training and 25% for testing.

- **Hyperparameter Tuning**
The hyperparameters were the set to determine the bes possible value for the Logistic Regression classifier. The 2 main hyperparameters uses were the `inverse of regularization strength(C)` and the `max_iter`.  For C,a uniform range between 0.5 and 2.0 was chosen while for the maximum iterarions, 4 discrete values; [10, 20, 25, 50] were chosen.
The termination policy chosen was the BanditPolicy that is based on the slack factor amount. The slack amount used was 0.1 and an evaluation interval of 2.

- **Classification Algorithm**
To perform the binary classification on the dataset, Logistic Regression was chosen as the classification algorithm.

**What are the benefits of the parameter sampler you chose?**
Random Parameter Sampling supports both continuous and discrete hyperparameters. It also supports early stopping which saves time and computing resources.

**What are the benefits of the early stopping policy you chose?**
Early stopping improves computational efficiency and saves time by terminating training runs that perform poorly.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
VotingEnsemble was the best model generated by AutoML. 


## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
